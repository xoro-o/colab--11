{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Some_PyTorch_Stuff",
      "provenance": [],
      "authorship_tag": "ABX9TyPmo9RoUirSuWeFVtUDhRuO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xoro-o/colab--11/blob/main/Some_PyTorch_Stuff.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iClAUVpmhEkN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X_train = np.arange(10,dtype='float32').reshape((10,1))\n",
        "y_train = np.array([1.0,1.3,3.1,2.0,5.0,6.3,6.6,7.4,8.0,9.0],dtype='float32')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(X_train,y_train,'x',markersize=10)  \n",
        "plt.xlabel('x',color='white')\n",
        "plt.ylabel('y',color='white')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "_gERD5GMhgTu",
        "outputId": "4d4f7ffa-77e3-4336-d65a-b91c12955a4e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now we standardize and create tensors for the input and labels\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "X_train_norm = (X_train-np.mean(X_train))/np.std(X_train)\n",
        "X_train_norm = torch.from_numpy(X_train_norm)\n",
        "y_train = torch.from_numpy(y_train)\n",
        "train_ds = TensorDataset(X_train_norm,y_train)\n",
        "batch_size = 1\n",
        "train_dl = DataLoader(train_ds,batch_size,shuffle=True)"
      ],
      "metadata": {
        "id": "iQqTVnbJhr-T"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1)\n",
        "weight = torch.rand(1)\n",
        "weight.requires_grad_()\n",
        "bias = torch.zeros(1,requires_grad = True)\n",
        "def model(x_batch):\n",
        "  return x_batch @ weight + bias"
      ],
      "metadata": {
        "id": "YzZQ8kSfiz9V"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(input,target):\n",
        "  return (input-target).pow(2).mean()"
      ],
      "metadata": {
        "id": "CO2HSQ4-kSFP"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "num_epochs = 200\n",
        "log_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "  for x_batch,y_batch in train_dl:\n",
        "    pred = model(x_batch)\n",
        "    loss = loss_fn(pred,y_batch)\n",
        "    loss.backward()\n",
        "  with torch.no_grad():\n",
        "    weight -= weight.grad*learning_rate\n",
        "    bias -= bias.grad*learning_rate\n",
        "    weight.grad.zero_()\n",
        "    bias.grad.zero_()\n",
        "  if(epoch % log_epochs):\n",
        "    print(f'Epoch {epoch}, loss {loss.item():.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cbtz-gHRkalM",
        "outputId": "756e13d7-d346-477e-e05a-26f1be85a577"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, loss 12.7045\n",
            "Epoch 2, loss 42.2612\n",
            "Epoch 3, loss 31.6346\n",
            "Epoch 4, loss 11.4468\n",
            "Epoch 5, loss 3.5311\n",
            "Epoch 6, loss 35.7048\n",
            "Epoch 7, loss 34.2280\n",
            "Epoch 8, loss 3.3678\n",
            "Epoch 9, loss 38.5479\n",
            "Epoch 11, loss 24.3872\n",
            "Epoch 12, loss 34.0026\n",
            "Epoch 13, loss 21.4849\n",
            "Epoch 14, loss 31.2694\n",
            "Epoch 15, loss 2.1533\n",
            "Epoch 16, loss 2.5655\n",
            "Epoch 17, loss 18.4224\n",
            "Epoch 18, loss 19.3631\n",
            "Epoch 19, loss 25.3449\n",
            "Epoch 21, loss 18.1422\n",
            "Epoch 22, loss 0.7659\n",
            "Epoch 23, loss 16.7578\n",
            "Epoch 24, loss 16.1060\n",
            "Epoch 25, loss 5.6720\n",
            "Epoch 26, loss 13.0648\n",
            "Epoch 27, loss 14.5280\n",
            "Epoch 28, loss 1.0872\n",
            "Epoch 29, loss 8.8481\n",
            "Epoch 31, loss 1.5720\n",
            "Epoch 32, loss 4.5438\n",
            "Epoch 33, loss 11.2783\n",
            "Epoch 34, loss 13.4183\n",
            "Epoch 35, loss 10.4216\n",
            "Epoch 36, loss 8.9575\n",
            "Epoch 37, loss 1.3032\n",
            "Epoch 38, loss 0.6146\n",
            "Epoch 39, loss 8.0068\n",
            "Epoch 41, loss 3.4524\n",
            "Epoch 42, loss 9.2393\n",
            "Epoch 43, loss 5.5944\n",
            "Epoch 44, loss 6.6489\n",
            "Epoch 45, loss 8.3586\n",
            "Epoch 46, loss 0.9937\n",
            "Epoch 47, loss 2.8949\n",
            "Epoch 48, loss 5.7801\n",
            "Epoch 49, loss 0.9104\n",
            "Epoch 51, loss 0.2674\n",
            "Epoch 52, loss 4.8255\n",
            "Epoch 53, loss 4.0976\n",
            "Epoch 54, loss 0.7894\n",
            "Epoch 55, loss 0.7676\n",
            "Epoch 56, loss 4.2849\n",
            "Epoch 57, loss 3.6329\n",
            "Epoch 58, loss 3.5266\n",
            "Epoch 59, loss 4.5238\n",
            "Epoch 61, loss 3.5793\n",
            "Epoch 62, loss 1.9146\n",
            "Epoch 63, loss 2.9086\n",
            "Epoch 64, loss 0.2658\n",
            "Epoch 65, loss 4.9689\n",
            "Epoch 66, loss 1.7266\n",
            "Epoch 67, loss 3.1614\n",
            "Epoch 68, loss 1.6415\n",
            "Epoch 69, loss 0.0606\n",
            "Epoch 71, loss 0.5027\n",
            "Epoch 72, loss 4.1959\n",
            "Epoch 73, loss 4.0990\n",
            "Epoch 74, loss 1.4172\n",
            "Epoch 75, loss 1.6397\n",
            "Epoch 76, loss 2.0949\n",
            "Epoch 77, loss 0.4342\n",
            "Epoch 78, loss 0.0206\n",
            "Epoch 79, loss 3.5778\n",
            "Epoch 81, loss 3.4248\n",
            "Epoch 82, loss 1.5827\n",
            "Epoch 83, loss 1.1011\n",
            "Epoch 84, loss 1.7303\n",
            "Epoch 85, loss 1.4949\n",
            "Epoch 86, loss 3.0812\n",
            "Epoch 87, loss 0.8143\n",
            "Epoch 88, loss 0.8380\n",
            "Epoch 89, loss 1.0126\n",
            "Epoch 91, loss 0.9716\n",
            "Epoch 92, loss 2.7323\n",
            "Epoch 93, loss 2.6801\n",
            "Epoch 94, loss 1.1591\n",
            "Epoch 95, loss 0.8966\n",
            "Epoch 96, loss 0.8793\n",
            "Epoch 97, loss 1.2709\n",
            "Epoch 98, loss 0.0008\n",
            "Epoch 99, loss 1.2156\n",
            "Epoch 101, loss 0.0023\n",
            "Epoch 102, loss 0.3960\n",
            "Epoch 103, loss 0.7612\n",
            "Epoch 104, loss 0.7574\n",
            "Epoch 105, loss 0.0053\n",
            "Epoch 106, loss 2.1238\n",
            "Epoch 107, loss 0.7707\n",
            "Epoch 108, loss 0.4327\n",
            "Epoch 109, loss 0.2249\n",
            "Epoch 111, loss 0.2304\n",
            "Epoch 112, loss 0.6632\n",
            "Epoch 113, loss 0.6503\n",
            "Epoch 114, loss 0.8937\n",
            "Epoch 115, loss 0.2034\n",
            "Epoch 116, loss 0.2790\n",
            "Epoch 117, loss 0.8450\n",
            "Epoch 118, loss 0.1454\n",
            "Epoch 119, loss 0.0215\n",
            "Epoch 121, loss 1.5063\n",
            "Epoch 122, loss 0.4970\n",
            "Epoch 123, loss 0.1799\n",
            "Epoch 124, loss 1.5542\n",
            "Epoch 125, loss 1.5697\n",
            "Epoch 126, loss 1.5849\n",
            "Epoch 127, loss 1.5999\n",
            "Epoch 128, loss 0.3089\n",
            "Epoch 129, loss 0.0634\n",
            "Epoch 131, loss 0.6662\n",
            "Epoch 132, loss 0.2687\n",
            "Epoch 133, loss 0.6460\n",
            "Epoch 134, loss 0.6363\n",
            "Epoch 135, loss 0.0856\n",
            "Epoch 136, loss 0.0336\n",
            "Epoch 137, loss 1.7376\n",
            "Epoch 138, loss 0.4616\n",
            "Epoch 139, loss 0.0643\n",
            "Epoch 141, loss 1.3315\n",
            "Epoch 142, loss 0.0512\n",
            "Epoch 143, loss 0.4367\n",
            "Epoch 144, loss 0.0556\n",
            "Epoch 145, loss 0.2739\n",
            "Epoch 146, loss 0.2675\n",
            "Epoch 147, loss 0.1618\n",
            "Epoch 148, loss 0.0311\n",
            "Epoch 149, loss 0.1307\n",
            "Epoch 151, loss 1.8958\n",
            "Epoch 152, loss 0.1374\n",
            "Epoch 153, loss 0.3954\n",
            "Epoch 154, loss 1.1788\n",
            "Epoch 155, loss 1.1690\n",
            "Epoch 156, loss 1.9436\n",
            "Epoch 157, loss 0.0125\n",
            "Epoch 158, loss 0.3784\n",
            "Epoch 159, loss 0.0736\n",
            "Epoch 161, loss 1.1147\n",
            "Epoch 162, loss 0.0065\n",
            "Epoch 163, loss 0.0000\n",
            "Epoch 164, loss 0.0789\n",
            "Epoch 165, loss 0.1132\n",
            "Epoch 166, loss 0.1741\n",
            "Epoch 167, loss 0.1707\n",
            "Epoch 168, loss 0.1106\n",
            "Epoch 169, loss 0.4191\n",
            "Epoch 171, loss 2.0636\n",
            "Epoch 172, loss 0.0867\n",
            "Epoch 173, loss 0.3380\n",
            "Epoch 174, loss 1.0207\n",
            "Epoch 175, loss 1.0146\n",
            "Epoch 176, loss 0.0045\n",
            "Epoch 177, loss 0.3914\n",
            "Epoch 178, loss 0.3883\n",
            "Epoch 179, loss 0.1375\n",
            "Epoch 181, loss 2.1271\n",
            "Epoch 182, loss 0.0003\n",
            "Epoch 183, loss 2.1384\n",
            "Epoch 184, loss 0.0996\n",
            "Epoch 185, loss 0.3685\n",
            "Epoch 186, loss 0.0010\n",
            "Epoch 187, loss 0.9512\n",
            "Epoch 188, loss 0.1191\n",
            "Epoch 189, loss 0.9422\n",
            "Epoch 191, loss 0.1140\n",
            "Epoch 192, loss 0.1123\n",
            "Epoch 193, loss 0.0158\n",
            "Epoch 194, loss 2.1936\n",
            "Epoch 195, loss 0.0941\n",
            "Epoch 196, loss 0.0936\n",
            "Epoch 197, loss 0.9101\n",
            "Epoch 198, loss 0.0049\n",
            "Epoch 199, loss 0.1021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "loss_fn = nn.MSELoss(reduction='mean')\n",
        "input_size = 1\n",
        "output_size = 1\n",
        "model = nn.Linear(input_size,output_size)\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr = 0.001)"
      ],
      "metadata": {
        "id": "6vB2umsIlv2V"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "  for x,y in train_dl:\n",
        "    pred = model(x)[:,0]\n",
        "    loss = loss_fn(pred,y)\n",
        "    loss.backward()\n",
        "    optimizer.step() \n",
        "    optimizer.zero_grad()\n",
        "  if(epoch%10 ==0):\n",
        "    print(f'Epoch : {epoch} loss : {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Loe39DIRoRlX",
        "outputId": "06fc18e3-b850-4e97-e05c-18b5fc4a8841"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 0 loss : 0.1086\n",
            "Epoch : 10 loss : 0.1012\n",
            "Epoch : 20 loss : 0.0268\n",
            "Epoch : 30 loss : 0.0217\n",
            "Epoch : 40 loss : 0.2994\n",
            "Epoch : 50 loss : 0.0860\n",
            "Epoch : 60 loss : 0.7993\n",
            "Epoch : 70 loss : 0.1274\n",
            "Epoch : 80 loss : 0.0584\n",
            "Epoch : 90 loss : 0.0793\n",
            "Epoch : 100 loss : 0.0085\n",
            "Epoch : 110 loss : 0.2634\n",
            "Epoch : 120 loss : 2.4092\n",
            "Epoch : 130 loss : 0.7554\n",
            "Epoch : 140 loss : 0.2588\n",
            "Epoch : 150 loss : 0.7508\n",
            "Epoch : 160 loss : 0.0494\n",
            "Epoch : 170 loss : 0.0756\n",
            "Epoch : 180 loss : 0.0487\n",
            "Epoch : 190 loss : 0.1382\n",
            "Epoch : 200 loss : 0.0482\n",
            "Epoch : 210 loss : 0.7439\n",
            "Epoch : 220 loss : 2.4309\n",
            "Epoch : 230 loss : 0.0443\n",
            "Epoch : 240 loss : 0.0721\n",
            "Epoch : 250 loss : 0.2384\n",
            "Epoch : 260 loss : 0.0446\n",
            "Epoch : 270 loss : 0.0056\n",
            "Epoch : 280 loss : 0.7416\n",
            "Epoch : 290 loss : 0.2527\n",
            "Epoch : 300 loss : 0.2382\n",
            "Epoch : 310 loss : 0.0744\n",
            "Epoch : 320 loss : 0.1393\n",
            "Epoch : 330 loss : 0.1392\n",
            "Epoch : 340 loss : 0.0056\n",
            "Epoch : 350 loss : 0.0726\n",
            "Epoch : 360 loss : 0.0745\n",
            "Epoch : 370 loss : 0.0056\n",
            "Epoch : 380 loss : 0.1394\n",
            "Epoch : 390 loss : 0.2380\n",
            "Epoch : 400 loss : 0.2379\n",
            "Epoch : 410 loss : 0.0727\n",
            "Epoch : 420 loss : 0.0471\n",
            "Epoch : 430 loss : 0.0727\n",
            "Epoch : 440 loss : 2.4345\n",
            "Epoch : 450 loss : 0.2378\n",
            "Epoch : 460 loss : 0.0450\n",
            "Epoch : 470 loss : 0.7409\n",
            "Epoch : 480 loss : 0.2523\n",
            "Epoch : 490 loss : 0.0727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Parameters : ',model.weight.item(),model.bias.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhhEeL37o_ke",
        "outputId": "1aceb3ac-91c3-496f-8140-3e0fc482f320"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters :  2.706899404525757 4.9699201583862305\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "iris = load_iris()"
      ],
      "metadata": {
        "id": "X3uwUF0MqRUC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = iris['target']\n",
        "X = iris['data']"
      ],
      "metadata": {
        "id": "PPl9nmp6qnyf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 1./3,random_state = 1)"
      ],
      "metadata": {
        "id": "NgRS6s-j6BXE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "X_train_norm = (X_train - np.mean(X_train))/np.std(X_train)\n",
        "X_train_norm = torch.from_numpy(X_train_norm).float()\n",
        "y_train = torch.from_numpy(y_train)\n",
        "train_ds = TensorDataset(X_train_norm,y_train)\n",
        "torch.manual_seed(1)\n",
        "batch_size = 2\n",
        "train_dl = DataLoader(train_ds,batch_size,shuffle=True)"
      ],
      "metadata": {
        "id": "zMNQ7smH6J1o"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size,output_size):\n",
        "    super().__init__()\n",
        "    self.layer1 = nn.Linear(input_size,hidden_size)\n",
        "    self.layer2 = nn.Linear(hidden_size,output_size)\n",
        "  def forward(self,x):\n",
        "    x = self.layer1(x)\n",
        "    x = nn.Sigmoid()(x)\n",
        "    x = self.layer2(x)\n",
        "    x = nn.Softmax(dim=1)(x)\n",
        "    return x \n",
        "  "
      ],
      "metadata": {
        "id": "nw_4sO-a66o7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = X_train_norm.shape[1]\n",
        "hidden_size = 16\n",
        "output_size = 3\n",
        "model = Model(input_size,hidden_size,output_size)\n"
      ],
      "metadata": {
        "id": "1h7z2xjr7_HZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)"
      ],
      "metadata": {
        "id": "dCGdxjsD8LxQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sequential api \n",
        "class MyModule(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    l1 = nn.Linear(2,4)\n",
        "    a1 = nn.ReLU()\n",
        "    l2 = nn.Linear(4,4)\n",
        "    a2 = nn.ReLU()\n",
        "    l3 = nn.Linear(4,1)\n",
        "    a3 = nn.Sigmoid()\n",
        "    l = [l1,a1,l2,a2,l3,a3]\n",
        "    self.module_list = nn.ModuleList(l)\n",
        "  def forward(self,x):\n",
        "    for f in self.module_list :\n",
        "      x = f(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "model = MyModule()\n",
        "model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANsPlOT68h0R",
        "outputId": "7fcc8591-9e84-4f5c-ca6c-2d5929801697"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyModule(\n",
              "  (module_list): ModuleList(\n",
              "    (0): Linear(in_features=2, out_features=4, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
              "    (5): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#custom layers!\n",
        "#here we created a new layer that was not supported by PyTorch \n",
        "#now we can create new models that use these layer\n",
        "class NoisyLayer(nn.Module):\n",
        "  def __init__(self,input_size,output_size,noise=0.01):\n",
        "    super().__init__()\n",
        "    w = torch.tensor(input_size,output_size)\n",
        "    self.w = nn.Parameter(w)\n",
        "    nn.init.xavier_uniform_(self.w)\n",
        "    b = torch.tensor(output_size).fill_(0)\n",
        "    self.b = nn.Parameter(b)\n",
        "    self.noise = noise\n",
        "  def forward(self,x,training=False):\n",
        "    if training:\n",
        "      noise = torch.normal(0.0,self.noise,x.shape)\n",
        "      x_new = torch.add(x,noise)\n",
        "    else:\n",
        "      x_new = x\n",
        "    return torch.add(torch.matmul(x_new,self.w),self.b)\n"
      ],
      "metadata": {
        "id": "s036b_iMXw9e"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lets create a new model using sequential method which uses the newly created NoisyLayer\n",
        "class MyNoisyModule(nn.Module):\n",
        "  def __init__(self):\n",
        "    # creating a NoisyLayer __init__\n",
        "    self.l1 = NoisyLayer(2,4,0.07)\n",
        "    #\n",
        "    self.a1 = nn.ReLU()\n",
        "    self.l2 = nn.Linear(4,3)\n",
        "    self.a2 = nn.ReLU()\n",
        "    self.l3 = nn.Linear(3,2)\n",
        "    self.a3 = nn.Sigmoid()\n",
        "  def forward(self,x,training = False):\n",
        "    #calling forward pass for noisy layer\n",
        "    x = self.l1(x,training)\n",
        "    #\n",
        "    x = self.a1(x)\n",
        "    x = self.l2(x)\n",
        "    x = self.a2(x)\n",
        "    x = self.l3(x)\n",
        "    x = self.a3(x)\n",
        "    return x\n",
        "  def predict(self,x):\n",
        "    x = torch.tensor(x,dtype = torch.float32)\n",
        "    pred = self.forward(x)\n",
        "    return (pred>=0.5).float()\n",
        "    \n"
      ],
      "metadata": {
        "id": "_vITcEMueJKv"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "H3Q4jfkvf-U1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}